{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo[srv] in c:\\users\\ram\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.10.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\ram\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pymongo[srv]) (2.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pymongo 4.10.1 does not provide the extra 'srv'\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install \"pymongo[srv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "# Task 1: Extracting the data (emails and dates)\n",
    "def extract_emails_and_dates(log_file_path):\n",
    "    email_regex = r'^From\\s+([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,})'\n",
    "    date_regex = r'^Date:\\s+(.+)'  # Matches \"Date: Sat, 5 Jan 2008 09:12:18 -0500\"\n",
    "    extracted_data = []\n",
    "\n",
    "    with open(log_file_path, 'r', encoding='utf-8') as file:\n",
    "        email = None\n",
    "        date = None\n",
    "\n",
    "        for line in file:\n",
    "            try:\n",
    "                email_match = re.search(email_regex, line)\n",
    "                date_match = re.search(date_regex, line)\n",
    "\n",
    "                if email_match:\n",
    "                    email = email_match.group(1)  # Extract email\n",
    "\n",
    "                if date_match:\n",
    "                    date = date_match.group(1)  # Extract date\n",
    "\n",
    "                if email and date:\n",
    "                    extracted_data.append({'email': email, 'date': date})\n",
    "                    email, date = None, None  # Reset for the next entry\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {line.strip()} - {e}\")\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# Task 2: Transforming the data (standardizing date format)\n",
    "def transform_data(extracted_data):\n",
    "    transformed_data = []\n",
    "    \n",
    "    for record in extracted_data:\n",
    "        try:\n",
    "            date_str = record['date']\n",
    "            \n",
    "            # Remove any text inside parentheses (optional extra info)\n",
    "            date_str = re.sub(r'\\(.*?\\)', '', date_str).strip()\n",
    "\n",
    "            # List of possible date formats to try\n",
    "            date_formats = [\n",
    "                \"%Y-%m-%d %H:%M:%S %z\",  # 2008-01-05 09:12:07 -0500\n",
    "                \"%a, %d %b %Y %H:%M:%S %z\"  # Sat, 5 Jan 2008 09:12:18 -0500\n",
    "            ]\n",
    "            \n",
    "            # Try parsing with different formats\n",
    "            for date_format in date_formats:\n",
    "                try:\n",
    "                    date = datetime.strptime(date_str, date_format)\n",
    "                    transformed_data.append({\n",
    "                        'email': record['email'],\n",
    "                        'date': date.strftime('%Y-%m-%d %H:%M:%S')  # Standardized format\n",
    "                    })\n",
    "                    break  # Stop after successful parsing\n",
    "                except ValueError:\n",
    "                    continue  # Try the next format\n",
    "            \n",
    "            else:\n",
    "                # If no format matched, print an error\n",
    "                print(f\"Skipping invalid date: {record['date']} - No valid format found\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping invalid date: {record['date']} - Error: {e}\")\n",
    "            continue  # Skip invalid date entries\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "# Task 3: Save the data to MongoDB\n",
    "uri = \"mongodb+srv://ram:2000@cluster0.5dmxi.mongodb.net/?retryWrites=true&w=majority&appName=Cluster1\"  # MongoDB connection URI\n",
    "# def save_to_mongodb(data, db_name='logs', collection_name='user_history'):\n",
    "#     client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "#     db = client[db_name]\n",
    "#     collection = db[collection_name]\n",
    "#     collection.insert_many(data)\n",
    "#     print(f\"Inserted {len(data)} records into MongoDB collection '{collection_name}'.\")\n",
    "def save_to_mongodb(data, db_name='test_db', collection_name='user_history'):\n",
    "    try:\n",
    "        client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "        db = client[db_name]  # MongoDB automatically creates the database if it doesn't exist\n",
    "\n",
    "        # Explicitly create the collection if it doesn't exist\n",
    "        collection = db.get_collection(collection_name)\n",
    "\n",
    "        # Now insert the data\n",
    "        if data:\n",
    "            result = collection.insert_many(data)\n",
    "            print(f\"Inserted {len(result.inserted_ids)} records into MongoDB collection '{collection_name}'.\")\n",
    "        else:\n",
    "            print(f\"No data to insert into MongoDB collection '{collection_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during MongoDB connection or data insertion: {e}\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "log_file_path = r'C:\\Users\\Ram\\Downloads\\mbox.txt'  # Replace with your actual log file path\n",
    "\n",
    "# Step 1: Extract emails and dates from the log file\n",
    "extracted_data = extract_emails_and_dates(log_file_path)\n",
    "print(f\"Extracted data: {extracted_data}\")\n",
    "\n",
    "# Step 2: Transform the extracted data (standardizing the date format)\n",
    "transformed_data = transform_data(extracted_data)\n",
    "print(f\"Transformed data: {transformed_data}\")\n",
    "\n",
    "# Step 3: Save the transformed data to MongoDB\n",
    "save_to_mongodb(transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 4\n",
    "\n",
    "from pymongo import MongoClient\n",
    "import mysql.connector\n",
    "\n",
    "def fetch_from_mongodb(mongo_uri='mongodb+srv://ram:2000@cluster0.5dmxi.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0', db_name='logs', collection_name='user_history'):\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    return list(collection.find({}, {'_id': 0}))\n",
    "\n",
    "def save_to_mysql(data, table_name='user_history'):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        port=3306,  # Default MySQL port\n",
    "        user=\"root\",  \n",
    "        password=\"\",  \n",
    "        database=\"test\" \n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create table\n",
    "    cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            email VARCHAR(255) NOT NULL,\n",
    "            date DATETIME NOT NULL\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    # Insert data\n",
    "    cursor.executemany(f\"\"\"\n",
    "        INSERT INTO {table_name} (email, date) VALUES (%s, %s);\n",
    "    \"\"\", [(record['email'], record['date']) for record in data])\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Inserted {len(data)} records into MySQL table '{table_name}'.\")\n",
    "\n",
    "# Test the function\n",
    "mongodb_data = fetch_from_mongodb()\n",
    "save_to_mysql(mongodb_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        port=3306,  # Default MySQL port\n",
    "        user=\"root\",  \n",
    "        password=\"\",  \n",
    "        database=\"test\" \n",
    "    )\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# 1. List All Unique Email Addresses\n",
    "query = \"SELECT DISTINCT email FROM user_history;\"\n",
    "cursor.execute(query)\n",
    "unique_emails = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(unique_emails, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Count the Total Number of Emails in the Table\n",
    "query = \"SELECT COUNT(*) AS total_emails FROM user_history;\"\n",
    "cursor.execute(query)\n",
    "total_emails = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(total_emails, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Count the Number of Emails Received Per Day\n",
    "query = \"\"\"\n",
    "    SELECT DATE(date) AS email_date, COUNT(*) AS email_count \n",
    "    FROM user_history \n",
    "    GROUP BY email_date;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "emails_per_day = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(emails_per_day, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT email, \n",
    "           MIN(date) AS first_email_date, \n",
    "           MAX(date) AS last_email_date \n",
    "    FROM user_history \n",
    "    GROUP BY email;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "email_dates = cursor.fetchall()\n",
    "\n",
    "# Extract headers from cursor description\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Print results in tabulated format\n",
    "print(tabulate(email_dates, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Count the Total Number of Emails Sent from Each Domain\n",
    "query = \"\"\"\n",
    "    SELECT SUBSTRING_INDEX(email, '@', -1) AS domain, COUNT(*) AS email_count \n",
    "    FROM user_history \n",
    "    GROUP BY domain;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "emails_per_domain = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(emails_per_domain, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Retrieve All Emails Sent in a Specific Date Range\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM user_history \n",
    "    WHERE date BETWEEN '2007-10-10' AND '2007-12-10';\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "emails_in_range = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(emails_in_range, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Find the Most Active Email Address (Max Emails Sent)\n",
    "query = \"\"\"\n",
    "    SELECT email, COUNT(*) AS email_count \n",
    "    FROM user_history \n",
    "    GROUP BY email \n",
    "    ORDER BY email_count DESC \n",
    "    LIMIT 1;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "most_active_email = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(most_active_email, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Find Emails Received on Weekends\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM user_history \n",
    "    WHERE DAYOFWEEK(date) IN (1, 7);  -- 1 = Sunday, 7 = Saturday\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "weekend_emails = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(weekend_emails, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Count Emails Per Hour of the Day\n",
    "query = \"\"\"\n",
    "    SELECT HOUR(date) AS hour_of_day, COUNT(*) AS email_count \n",
    "    FROM user_history \n",
    "    GROUP BY hour_of_day \n",
    "    ORDER BY hour_of_day;\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "emails_per_hour = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(emails_per_hour, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Retrieve Emails Sent by a Specific Domain\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM user_history \n",
    "    WHERE email LIKE '%@gmail.com';\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "gmail_emails = cursor.fetchall()\n",
    "headers = [desc[0] for desc in cursor.description]\n",
    "print(tabulate(gmail_emails, headers=headers, tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
